# K8s memo:

kubernetesの主な機能

| name | override |
| --- | --- |
| スケーリング/オートスケーリング | コンテナクラスタを形成し、複数のNodeを管理します。 |
| スケジューリング | コンテナをデプロイする際、どのNodeに配置するかを決定する。（例、「ディスクIOが多い」コンテナを「ディスクがSSD」のNodeに配置する。 |
| リソース管理 | コンテナ配置の為の特別な指定がない場合には、NodeのCPUやメモリの秋リソースの状況に従ってスケジューリングが行われる。その為ユーザーが意識する必要がありません。 |
| セルフヒーリング | 標準でコンテナのプロセス監視が行われている。プロセスの停止を検知すると、再度コンテナのスケジューリングを実行することで自動的にコンテナを再デプロイします。クラスタのNode障害が起きたり、Node退避を行ったりして、Node上のコンテナが失われた場合であっても、サービスに影響なくアプリケーションを自動復旧を行います。 |
| サービスディスカバリとロードバランシング | コンテナをスケーリングさせた場合、アプリケーションへ接続するためのエンドポイントの問題を解消する為、ロードバランシング機能（Service）があらかじめ指定した条件に合致するコンテナ群に対してルーティングを行う機能を提供します。また、Serviceを利用することでサービスディスカバリを行うことも可能です。 |
| データの管理 | データストアにetcdを採用しています。etcdはクラスタを組むことで冗長化ができる為、コンテナやServiceに関するマニフェストも冗長化された保存されています。kubernetesにはコンテナが利用する設定ファイルや認証情報などのデータを保存する仕組みが用意されています。 |

## 始めてみよう

コンテナのデプロイからサービスの外部公開するまで、Kubernetesではたったの2ステップです。


今回はnginexのサーバーのコンテナを3つ起動しロードバランサーを紐づけし外部公開を行います。

ロードバランサーを作成するとサービス公開に必要なIPアドレスが払いだされる。自動的に3つのコンテナへの負荷分散された状態になります。

```bash
# nginxコンテナ3つからなるグループを作成しmyappラベルもつけておく
> kubectl run myapp \
	--image=nginx:1.12 \
	--replicas 3 \
	--labels="app=myapp"

> kubectl create service loadbalancer \
	--tcp 80:80 myapp

# 外部アクセスする為のIP Addressを取得
> kubectl get service myapp

```
